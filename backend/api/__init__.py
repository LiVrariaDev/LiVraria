"""
Backend API module initialization
LangChainãƒ™ãƒ¼ã‚¹ã®LLMçµ±åˆ
"""
import os
import logging

# ãƒ­ã‚¬ãƒ¼è¨­å®š
logger = logging.getLogger("uvicorn.error")

# LangChainãƒ™ãƒ¼ã‚¹ã®LLMé–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from .llm import llm_chat as chat_function
from .llm import llm_summary as summary_function

# LLMãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®é¸æŠï¼ˆGeminiã¾ãŸã¯Ollamaï¼‰
LLM_BACKEND = os.getenv("LLM_BACKEND", "gemini")

if LLM_BACKEND == "ollama":
	logger.info(f"ğŸ”§ [LLM Backend] LangChain + Ollama (model: {os.getenv('OLLAMA_MODEL', 'llama3.2')})")
else:
	logger.info("ğŸ”§ [LLM Backend] LangChain + Gemini")

__all__ = ['chat_function', 'summary_function', 'LLM_BACKEND']
