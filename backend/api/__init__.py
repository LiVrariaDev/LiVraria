"""
Backend API module initialization
LLMãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®é¸æŠã‚’ä¸€å…ƒç®¡ç†
"""
import os
import logging

# ãƒ­ã‚¬ãƒ¼è¨­å®š
logger = logging.getLogger("uvicorn.error")

# LLMãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®é¸æŠ
LLM_BACKEND = os.getenv("LLM_BACKEND", "gemini")

if LLM_BACKEND == "ollama":
	from .llm import llm_chat as chat_function
	from .llm import llm_summary as summary_function
	logger.info(f"ğŸ”§ [LLM Backend Init] Ollama selected (model: {os.getenv('OLLAMA_MODEL', 'llama3.2')})")
else:
	from .gemini import gemini_chat as chat_function
	from .gemini import gemini_summary as summary_function
	logger.info("ğŸ”§ [LLM Backend Init] Gemini selected")

__all__ = ['chat_function', 'summary_function', 'LLM_BACKEND']
